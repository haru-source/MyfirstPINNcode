# -*- coding: utf-8 -*-
import torch
import torch.nn as nn
import matplotlib.pyplot as plt


class SimplePINN(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(1, 20),
            nn.Tanh(),
            nn.Linear(20, 20),
            nn.Tanh(),
            nn.Linear(20, 1)
        )
        # 周波数パラメータ ω を学習させる
        self.omega = nn.Parameter(torch.tensor(1.0))  # 初期値1.0（学習で最適化）

    def forward(self, t):
        return self.net(t)

# 損失関数（PINNで物理方程式を満たすように）
def physics_loss(model, t):
    t.requires_grad_(True)
    x = model(t)
    dx = torch.autograd.grad(x, t, torch.ones_like(x), create_graph=True)[0]
    d2x = torch.autograd.grad(dx, t, torch.ones_like(dx), create_graph=True)[0]
    
    # f = m*a + k*x = 0 → a + ω^2 * x = 0
    residual = d2x + (model.omega**2) * x
    return torch.mean(residual**2)


# モデルと最適化
model = SimplePINN()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# 学習用時間データ
t_train = torch.linspace(0, 2 * torch.pi, 100).reshape(-1, 1)

# 学習ループ
loss_list = []
for epoch in range(5000):
    optimizer.zero_grad()
    loss = physics_loss(model, t_train)
    loss.backward()
    optimizer.step()

    loss_list.append(loss.item())
    if epoch % 500 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.6f}, ω: {model.omega.item():.4f}")

# 結果表示
print(f"\n学習された周波数 ω: {model.omega.item():.6f}")

# Lossの推移
plt.plot(loss_list)
plt.xlabel('Epoch')
plt.ylabel('Physics Loss')
plt.title('Training Loss')
plt.grid(True)
plt.show()

